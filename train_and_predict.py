import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
import lightgbm as lgb
import gc
import seaborn as sns
from joblib import load, dump
from sklearn.model_selection import ShuffleSplit
from sklearn.metrics import roc_auc_score

TRAIN_OUTPUT_PATH = './train_kaggle_feature_engineered.pickle'
TEST_OUTPUT_PATH = './test_kaggle_feature_engineered.pickle'

# Reading previously feature engineered train dataset
train = pd.read_pickle(TRAIN_OUTPUT_PATH)

target = train['HasDetections']
del train['HasDetections']

# Creating splits
shuffle_split_tr = ShuffleSplit(n_splits=1, test_size=0.3, random_state=22)
shuffle_split_tr.get_n_splits(train, target)
train_idx, val_idx = next(shuffle_split_tr.split(train, target)) 

shuffle_split_val_test = ShuffleSplit(n_splits=1, test_size=0.5, random_state=22)
shuffle_split_val_test.get_n_splits(val_idx, target[val_idx])
val_idx, tst_idx = next(shuffle_split_val_test.split(val_idx, target[val_idx])) 

features = [c for c in train.columns if c not in ['MachineIdentifier']]

# Training stage
categorical_features = ['SmartScreen', 'Census_OSInstallTypeName', 'Census_ActivationChannel',
                        'Census_OSBranch', 'Census_OSSkuName', 'Wdft_RegionIdentifier', 
                        'Census_OSBuildRevision', 'IeVerIdentifier']

train_lgb = lgb.Dataset(train.iloc[train_idx][features],
                        label=target.iloc[train_idx],
                        categorical_feature = categorical_features
                       )

val_lgb = lgb.Dataset(train.iloc[val_idx][features],
                      label=target.iloc[val_idx],
                      categorical_feature = categorical_features
                     )

params = {'num_leaves': 60,
          'min_data_in_leaf': 60, 
          'objective':'binary',
          'max_depth': 8,
          'learning_rate': 0.1,
          'boosting': 'gbdt',
          'feature_fraction': 0.8,
          'bagging_freq': 1,
          'bagging_fraction': 0.8 ,
          'bagging_seed': 11,
          'metric': 'auc',
          'lambda_l1': 0.50,
          'random_state': 133,
          'verbosity': -1}

num_round = 3000
model = lgb.train(params,
                  train_lgb,
                  num_round,
                  valid_sets = [train_lgb, val_lgb],
                  verbose_eval = 100,
                  early_stopping_rounds = 200)                                                                                                                                                                          

dump(model, './malware_model_lgbm.pkl')

del train_lgb
del val_lgb

# Simple assessment
print('Training dataset:')
print( roc_auc_score(target[train_idx], model.predict(train.iloc[train_idx][features])) )

print('Validation dataset:')
print( roc_auc_score(target[val_idx], model.predict(train.iloc[val_idx][features])) )

print('Test dataset:')
print( roc_auc_score(target[tst_idx], model.predict(train.iloc[tst_idx][features])) )

del train

# Predicting probabilities for the submission dataset
test = pd.read_pickle(TEST_OUTPUT_PATH)
probs = model.predict(test[features], num_iteration=model.best_iteration)

sub_df = pd.DataFrame({'MachineIdentifier': test['MachineIdentifier'].values})
sub_df['HasDetections'] = probs

sub_df.to_csv('./malware_probs_submission.csv', index=False)
